{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65d276cf-70a6-4f4a-baaa-8c4c05dd3a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in d:\\anaconda3\\lib\\site-packages (0.3.13)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp313-cp313-win_amd64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: packaging in d:\\anaconda3\\lib\\site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: pyyaml in d:\\anaconda3\\lib\\site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\anaconda3\\lib\\site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda3\\lib\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: filelock in d:\\anaconda3\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in d:\\anaconda3\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in d:\\anaconda3\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda3\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2025.10.5)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Downloading torch-2.9.1-cp313-cp313-win_amd64.whl (110.9 MB)\n",
      "   ---------------------------------------- 0.0/110.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/110.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.6/110.9 MB 7.1 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 3.4/110.9 MB 7.8 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 6.3/110.9 MB 9.2 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 8.7/110.9 MB 9.7 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 11.0/110.9 MB 10.0 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 13.4/110.9 MB 10.2 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 15.7/110.9 MB 10.4 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 18.1/110.9 MB 10.5 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 20.4/110.9 MB 10.6 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 22.8/110.9 MB 10.7 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 25.2/110.9 MB 10.7 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 27.5/110.9 MB 10.8 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 29.9/110.9 MB 10.8 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 32.2/110.9 MB 10.9 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 34.6/110.9 MB 10.9 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 37.0/110.9 MB 10.9 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 39.3/110.9 MB 11.0 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 41.7/110.9 MB 11.0 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 44.0/110.9 MB 11.0 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 46.1/110.9 MB 11.0 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 48.5/110.9 MB 11.0 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 50.6/110.9 MB 10.9 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 52.7/110.9 MB 10.9 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 55.1/110.9 MB 10.9 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 57.4/110.9 MB 10.9 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 59.8/110.9 MB 10.9 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 62.1/110.9 MB 10.9 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 64.2/110.9 MB 11.0 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 66.6/110.9 MB 11.0 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 68.9/110.9 MB 11.0 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 71.3/110.9 MB 11.0 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 73.7/110.9 MB 11.0 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 76.0/110.9 MB 11.0 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 78.4/110.9 MB 11.0 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 80.5/110.9 MB 11.0 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 83.1/110.9 MB 11.0 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 85.2/110.9 MB 11.0 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 87.6/110.9 MB 11.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 90.2/110.9 MB 11.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 92.3/110.9 MB 11.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 94.9/110.9 MB 11.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 97.0/110.9 MB 11.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 99.6/110.9 MB 11.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 101.7/110.9 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 104.1/110.9 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 106.4/110.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  108.8/110.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  110.9/110.9 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------- 110.9/110.9 MB 10.9 MB/s eta 0:00:00\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.9.1\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a39307c-107e-4e2b-ab81-0af44a0cfaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/mar1mba/russian-sentiment-dataset?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 53.9M/53.9M [00:05<00:00, 9.78MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\balot\\.cache\\kagglehub\\datasets\\mar1mba\\russian-sentiment-dataset\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"mar1mba/russian-sentiment-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7abece0-ad7a-468a-8816-9153a1562a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# Set random seed to reproduct experimentations\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9f4f880-f5be-4724-9a0d-50f2bc69fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenize(text):\n",
    "    \"\"\"\n",
    "    Токенизируем текст. Убрать знаки, в один регистр и другая шляпа.\n",
    "    \"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^0-9a-zа-яё\\s]', ' ', text)\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "def build_vocab(tokenized_texts, max_vocab_size=20000, min_freq=1):\n",
    "    counter = Counter([tok for doc in tokenized_texts for tok in doc])  # в токенизированном тексте выбираем фрагменты doc и берем по токену\n",
    "    # убираем те что меньше минимальной частоты и сортируем по убыванию\n",
    "    if min_freq > 1:\n",
    "        items = [(w,c) for w,c in counter.items() if c >= min_freq]\n",
    "        items.sort(key=lambda x: x[1], reverse=True)\n",
    "    else:\n",
    "        items = counter.most_common()\n",
    "    items = items[:max_vocab_size-2]  # убираем последние чтобы поместить служебные токены\n",
    "    itos = ['<PAD>', '<UNK>'] + [w for w,c in items]  # берём слова из словаря и помещаем к ним служебные токены\n",
    "    stoi = {w:i for i,w in enumerate(itos)}  # слово - индекс словарь\n",
    "    return stoi, itos\n",
    "\n",
    "def encode_doc(tokens, stoi, max_len):\n",
    "    \"\"\"\n",
    "    Кодируем документ из словаря stoi\n",
    "    \"\"\"\n",
    "    seq = [stoi.get(t, 1) for t in tokens]  # Возращаем индекс, если есть в словаре. Иначе 1 --> <UNK>\n",
    "    if len(seq) >= max_len:  # режем слишком длинные последовательности\n",
    "        return seq[:max_len]\n",
    "    else:\n",
    "        return seq + [0]*(max_len - len(seq))  # дополняем нулями короткие. 0 --> <PAD>\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.X = torch.tensor(sequences, dtype=torch.long)\n",
    "        self.y = torch.tensor(labels, dtype=torch.long)  \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "047705ad-8e84-4670-ad2e-862bb9d852cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=128, hidden=128, bidir=False, num_classes=3):  # num_classes=3 для трёхклассовой классификации\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)  # слой эмбедингов\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=hidden,\n",
    "            bidirectional=bidir,  # используем параметр bidir\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.hidden_size = hidden * (2 if bidir else 1)  # скрытый слой\n",
    "        self.fc = nn.Linear(self.hidden_size, 128)  # промежуточный линейный слой преобразует размер входного вектора в 128\n",
    "        self.dropout = nn.Dropout(0.4)  # Выклюлючает 40% всех входов случайно. Нужен для предотвращения переобучения\n",
    "        self.out = nn.Linear(128, num_classes)  # финальный слой предсказания - 3 класса\n",
    "    \n",
    "    def forward(self, x):\n",
    "        e = self.embed(x)\n",
    "        _, (h_n, _) = self.lstm(e)  # нам нужны только финальные состояния слоёв (причём только скрытые), промежуточные в топку\n",
    "        if self.lstm.bidirectional:\n",
    "            h = torch.cat((h_n[-2], h_n[-1]), dim=1)  # конкатенируем forward и backward\n",
    "        else:\n",
    "            h = h_n[-1]  # последний слой\n",
    "        h = torch.relu(self.fc(h))  # линейно выравниваем и используем функцию активации relu для каждого ветора\n",
    "        h = self.dropout(h)  # to be Tanos\n",
    "        return self.out(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f7c7c49-5d53-4455-ac6d-4de47b0a6c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(xb)\n",
    "        loss = criterion(out, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()  # Переводим модель в режим оценки (отключаем dropout, batch norm и т.д.)\n",
    "    ys = []\n",
    "    yps = []\n",
    "    with torch.no_grad():  # Отключаем вычисление градиентов для ускорения и экономии памяти\n",
    "        for xb, yb in loader:  # Проходим по всем батчам. Распаковываем батч в xb - признаки, yb - метки\n",
    "            xb = xb.to(device)\n",
    "            out = model(xb).cpu().numpy()\n",
    "            yps.extend(out.tolist())\n",
    "            ys.extend(yb.numpy().tolist())\n",
    "    \n",
    "    y_true = np.array(ys)\n",
    "    y_prob = np.array(yps)\n",
    "    y_pred = np.argmax(y_prob, axis=1)  # для многоклассовой классификации используем argmax\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    # для 3 классов используем macro averaging для получения усредненных метрик по всем классам\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1': f1,\n",
    "        'cm': cm,\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred,\n",
    "        'y_prob': y_prob\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97290d10-0e69-43c6-8a62-fbe454edab75",
   "metadata": {},
   "source": [
    "# Основной пайплайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f5831cc-a723-4d4a-86b6-210599b69bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Unique labels in dataset: [0 1 2]\n",
      "Vocab size: 20000\n",
      "Train: 203320, Val: 29046, Test: 58092\n",
      "Train distribution: [67612 67814 67894]\n",
      "Val distribution: [9659 9688 9699]\n",
      "Test distribution: [19318 19375 19399]\n",
      "Epoch 1/10 — train_loss: 0.9895 | val_acc: 0.6230 | val_f1: 0.6124\n",
      "  Saved best model (val_f1=0.6124) -> best_model.pth\n",
      "Epoch 2/10 — train_loss: 0.7302 | val_acc: 0.6700 | val_f1: 0.6726\n",
      "  Saved best model (val_f1=0.6726) -> best_model.pth\n",
      "Epoch 3/10 — train_loss: 0.6576 | val_acc: 0.6896 | val_f1: 0.6908\n",
      "  Saved best model (val_f1=0.6908) -> best_model.pth\n",
      "Epoch 4/10 — train_loss: 0.6017 | val_acc: 0.6900 | val_f1: 0.6908\n",
      "  Saved best model (val_f1=0.6908) -> best_model.pth\n",
      "Epoch 5/10 — train_loss: 0.5442 | val_acc: 0.6900 | val_f1: 0.6910\n",
      "  Saved best model (val_f1=0.6910) -> best_model.pth\n",
      "Epoch 6/10 — train_loss: 0.4847 | val_acc: 0.6876 | val_f1: 0.6889\n",
      "Epoch 7/10 — train_loss: 0.4217 | val_acc: 0.6830 | val_f1: 0.6840\n",
      "Epoch 8/10 — train_loss: 0.3636 | val_acc: 0.6768 | val_f1: 0.6795\n",
      "Early stopping: no improvement for 3 epochs.\n",
      "\n",
      "Test results:\n",
      "  Accuracy: 0.6915\n",
      "  Precision (macro): 0.6936\n",
      "  Recall (macro): 0.6914\n",
      "  F1 (macro): 0.6924\n",
      "  Confusion matrix:\n",
      " [[11780  2980  4558]\n",
      " [ 3160 15208  1007]\n",
      " [ 5266   949 13184]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     class_0       0.58      0.61      0.60     19318\n",
      "     class_1       0.79      0.78      0.79     19375\n",
      "     class_2       0.70      0.68      0.69     19399\n",
      "\n",
      "    accuracy                           0.69     58092\n",
      "   macro avg       0.69      0.69      0.69     58092\n",
      "weighted avg       0.69      0.69      0.69     58092\n",
      "\n",
      "\n",
      "Results saved to results.json\n"
     ]
    }
   ],
   "source": [
    "def main(args):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"Device:\", device)\n",
    "    \n",
    "    if not os.path.exists(args.data_path):\n",
    "        raise FileNotFoundError(f\"Data file not found: {args.data_path}\")\n",
    "    \n",
    "    df = pd.read_csv(args.data_path)\n",
    "    if 'text' not in df.columns or 'label' not in df.columns:\n",
    "        raise ValueError(\"CSV must contain 'text' and 'label' columns.\")\n",
    "    \n",
    "    df = df.dropna(subset=['text']).reset_index(drop=True)\n",
    "    texts = df['text'].astype(str).tolist()\n",
    "    labels = df['label'].astype(int).values\n",
    "    \n",
    "    # Проверяем что метки находятся в диапазоне [0, 1, 2] для 3 классов\n",
    "    unique_labels = np.unique(labels)\n",
    "    print(f\"Unique labels in dataset: {unique_labels}\")\n",
    "    if not all(label in [0, 1, 2] for label in unique_labels):\n",
    "        print(\"Warning: Labels should be 0, 1, 2 for 3-class classification\")\n",
    "    \n",
    "    tokenized = [simple_tokenize(t) for t in texts]\n",
    "    stoi, itos = build_vocab(tokenized, max_vocab_size=args.max_vocab, min_freq=args.min_freq)\n",
    "    vocab_size = len(itos)\n",
    "    print(\"Vocab size:\", vocab_size)\n",
    "    \n",
    "    sequences = np.array([encode_doc(toks, stoi, args.max_len) for toks in tokenized], dtype=np.int64)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(sequences, labels, test_size=args.test_size, random_state=args.seed, stratify=labels)\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=args.val_size, random_state=args.seed, stratify=y_train)\n",
    "    \n",
    "    print(f\"Train: {len(X_tr)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "    \n",
    "    # Выводим распределение классов\n",
    "    print(f\"Train distribution: {np.bincount(y_tr)}\")\n",
    "    print(f\"Val distribution: {np.bincount(y_val)}\")\n",
    "    print(f\"Test distribution: {np.bincount(y_test)}\")\n",
    "    \n",
    "    train_loader = DataLoader(TextDataset(X_tr, y_tr), batch_size=args.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(TextDataset(X_val, y_val), batch_size=args.batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(TextDataset(X_test, y_test), batch_size=args.batch_size, shuffle=False)\n",
    "    \n",
    "    model = LSTMModel(vocab_size, emb_dim=args.emb_dim, hidden=args.lstm_hidden, bidir=args.bidir, num_classes=3).to(device)  # num_classes=3\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    \n",
    "    best_val_f1 = -1.0\n",
    "    epochs_without_improve = 0\n",
    "    history = {'train_loss': [], 'val_f1': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_metrics = evaluate(model, val_loader, device)\n",
    "        val_f1 = val_metrics['f1']\n",
    "        val_acc = val_metrics['accuracy']\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch}/{args.epochs} — train_loss: {train_loss:.4f} | val_acc: {val_acc:.4f} | val_f1: {val_f1:.4f}\")\n",
    "        \n",
    "        if val_f1 > best_val_f1:  # лучшая модель\n",
    "            best_val_f1 = val_f1\n",
    "            epochs_without_improve = 0\n",
    "            best_state = {\n",
    "                'model_state': model.state_dict(),\n",
    "                'optimizer_state': optimizer.state_dict(),\n",
    "                'args': vars(args)\n",
    "            }\n",
    "            torch.save(best_state, args.output_model_path)\n",
    "            print(f\"  Saved best model (val_f1={val_f1:.4f}) -> {args.output_model_path}\")\n",
    "        else:\n",
    "            epochs_without_improve += 1\n",
    "            if epochs_without_improve >= args.patience:\n",
    "                print(f\"Early stopping: no improvement for {args.patience} epochs.\")\n",
    "                break\n",
    "    \n",
    "    saved = torch.load(args.output_model_path, map_location=device, weights_only=False)\n",
    "    model.load_state_dict(saved['model_state'])\n",
    "    \n",
    "    test_metrics = evaluate(model, test_loader, device)\n",
    "    print(\"\\nTest results:\")\n",
    "    print(f\"  Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "    print(f\"  Precision (macro): {test_metrics['precision']:.4f}\")\n",
    "    print(f\"  Recall (macro): {test_metrics['recall']:.4f}\")\n",
    "    print(f\"  F1 (macro): {test_metrics['f1']:.4f}\")\n",
    "    print(\"  Confusion matrix:\\n\", test_metrics['cm'])\n",
    "    print(\"\\nClassification report:\\n\", classification_report(test_metrics['y_true'], test_metrics['y_pred'], target_names=['class_0','class_1','class_2'], zero_division=0))\n",
    "    \n",
    "    # Сохраняем результаты в JSON\n",
    "    results = {\n",
    "        'accuracy': float(test_metrics['accuracy']),\n",
    "        'precision': float(test_metrics['precision']),\n",
    "        'recall': float(test_metrics['recall']),\n",
    "        'f1': float(test_metrics['f1']),\n",
    "        'confusion_matrix': test_metrics['cm'].tolist(),\n",
    "        'history': history\n",
    "    }\n",
    "    with open(args.results_path, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    print(f\"\\nResults saved to {args.results_path}\")\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.data_path = f'{path}\\sentiment_dataset.csv'\n",
    "        self.max_vocab = 20000\n",
    "        self.min_freq = 1\n",
    "        self.max_len = 80\n",
    "        self.emb_dim = 128\n",
    "        self.lstm_hidden = 128\n",
    "        self.bidir = False\n",
    "        self.epochs = 10\n",
    "        self.batch_size = 64\n",
    "        self.lr = 1e-3\n",
    "        self.test_size = 0.2\n",
    "        self.val_size = 0.125\n",
    "        self.patience = 3\n",
    "        self.seed = 42\n",
    "        self.output_model_path = 'best_model.pth'\n",
    "        self.results_path = 'results.json'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = Args()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1c0b4b6-b0da-4e8d-b362-8b7ba15f665f",
   "metadata": {},
   "source": [
    "Интерпретация результатов модели\n",
    "Общая производительность\n",
    "\n",
    "    Accuracy: 69.15% - модель правильно классифицирует примерно 7 из 10 текстов\n",
    "    F1-score (macro): 69.24% - сбалансированная метрика показывает умеренное качество\n",
    "\n",
    "Анализ по классам\n",
    "\n",
    "Class 0 (наихудшие результаты):\n",
    "\n",
    "    Precision: 58% - из всех предсказаний класса 0, только 58% действительно относятся к этому классу\n",
    "    Recall: 61% - модель находит только 61% всех объектов класса 0\n",
    "    F1: 60% - самый слабый класс для модели\n",
    "    Проблема: Модель часто путает класс 0 с классами 1 (2,980 случаев) и 2 (4,558 случаев)\n",
    "\n",
    "Class 1 (лучшие результаты):\n",
    "\n",
    "    Precision: 79% - высокая точность предсказаний\n",
    "    Recall: 78% - хорошо находит объекты этого класса\n",
    "    F1: 79% - самый сильный класс\n",
    "    Причина успеха: Класс 1, вероятно, имеет более четкие и различимые признаки\n",
    "\n",
    "Class 2 (средние результаты):\n",
    "\n",
    "    Precision: 70%\n",
    "    Recall: 68%\n",
    "    F1: 69% - промежуточное качество\n",
    "    Проблема: Путается с классом 0 (5,266 случаев)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
